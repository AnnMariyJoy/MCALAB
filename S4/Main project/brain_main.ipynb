{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import Input\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to your dataset\n",
    "train_dir = 'C:\\\\Users\\\\ANN MARIYA\\\\Desktop\\\\main project\\\\Training'\n",
    "test_dir = 'C:\\\\Users\\\\ANN MARIYA\\\\Desktop\\\\main project\\\\Testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image properties\n",
    "img_size = (150, 150) # Defines the size of input images (width, height)\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,         \n",
    "    rotation_range=20,      \n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2, \n",
    "    shear_range=0.2,        \n",
    "    zoom_range=0.2,         \n",
    "    horizontal_flip=True,   \n",
    "    fill_mode='nearest'     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test data augmentation (only rescale)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 images belonging to 4 classes.\n",
      "Found 1311 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training dataset\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Load testing dataset\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n"
     ]
    }
   ],
   "source": [
    "# Get class names from the training data generator\n",
    "class_names = train_data.class_indices.keys()  \n",
    "print(\"Classes:\", list(class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(150, 150, 3)),  # Define input shape here\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_data.class_indices), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 547ms/step - accuracy: 0.8345 - loss: 0.4401 - val_accuracy: 0.7536 - val_loss: 0.7486\n",
      "Epoch 2/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 499ms/step - accuracy: 0.8495 - loss: 0.4115 - val_accuracy: 0.7780 - val_loss: 0.7059\n",
      "Epoch 3/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 506ms/step - accuracy: 0.8562 - loss: 0.3808 - val_accuracy: 0.7658 - val_loss: 0.6889\n",
      "Epoch 4/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 518ms/step - accuracy: 0.8493 - loss: 0.3772 - val_accuracy: 0.8238 - val_loss: 0.4286\n",
      "Epoch 5/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 480ms/step - accuracy: 0.8482 - loss: 0.3811 - val_accuracy: 0.8063 - val_loss: 0.5827\n",
      "Epoch 6/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 475ms/step - accuracy: 0.8729 - loss: 0.3546 - val_accuracy: 0.8360 - val_loss: 0.4268\n",
      "Epoch 7/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 483ms/step - accuracy: 0.8619 - loss: 0.3606 - val_accuracy: 0.8467 - val_loss: 0.4332\n",
      "Epoch 8/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 483ms/step - accuracy: 0.8768 - loss: 0.3275 - val_accuracy: 0.8398 - val_loss: 0.4392\n",
      "Epoch 9/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 483ms/step - accuracy: 0.8749 - loss: 0.3311 - val_accuracy: 0.8406 - val_loss: 0.4070\n",
      "Epoch 10/10\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 487ms/step - accuracy: 0.8887 - loss: 0.3090 - val_accuracy: 0.7971 - val_loss: 0.6066\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
